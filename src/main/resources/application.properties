#修改端口号
server.port=2685
#=============JDBC连接驱动配置===================#
#数据库连接驱动
spring.datasource.url=jdbc:mysql://localhost:3306/smbms?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC
#数据库名
spring.datasource.username=sakura
#数据库密码
spring.datasource.password=sakura
#加载驱动
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
#指定数据库类型
spring.jpa.database=mysql
#=============Mybatis-plus配置===================#
#配置mapper映射文件地址
mybatis.mapper-locations=classpath*:mybaties/mapper/*.xml
#配置实体类
mybatis.type-aliases-package=com.sakura.usermanage.entity
#=============RedisProperties.Jedis配置===================#
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=localhost
# Redis服务器连接密码（默认为空）
spring.redis.password=
#连接池最大连接数（使用负值表示没有限制）
spring.redis.jedis.pool.max-active=50
#连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=20
#连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=2
#=============  Kafka配置  ========================#
## 指定kafka 代理地址,目前指定为本地
#spring.kafka.bootstrap-servers=localhost
##=============== producer  =======================
## 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，
## 当retris为0时，produce不会重复。retirs重发，此时repli节点完全成为leader节点，不会产生消息丢失。
#spring.kafka.producer.retries=0
## 每次批量发送消息的数量,produce积累到一定数据，一次发送
#spring.kafka.producer.batch-size=16384
## produce积累数据一次发送，缓存大小达到buffer.memory就发送数据
#spring.kafka.producer.buffer-memory=33554432
##可以设置的值为：all, -1, 0, 1
#spring.kafka.producer.acks=1
## 指定消息key和消息体的编解码方式
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
##=============== consumer  =======================
## 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
#spring.kafka.consumer.group-id=testGroup
## smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
#spring.kafka.consumer.auto-offset-reset=earliest
## enable.auto.commit:true --> 设置自动提交offset
#spring.kafka.consumer.enable-auto-commit=true
##如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
#spring.kafka.consumer.auto-commit-interval=100
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer